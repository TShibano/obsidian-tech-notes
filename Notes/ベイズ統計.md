---
title: "ベイズ統計"
date: 2026-02-13
tags:
  - AI
  - ML
related:
  - "[[線型モデル]]"
  - "[[MLOps]]"
---

## 概要

ベイズ統計は、確率を「事象の発生頻度」ではなく「信念の度合い（Degree of Belief）」として解釈する統計学のパラダイム。事前知識（事前分布）と観測データ（尤度）をベイズの定理で組み合わせ、パラメータの事後分布を得る。データが少ない場面や不確実性の定量化が重要な場面で特に有効。

## 詳細

### ベイズの定理

$$P(\theta | \text{data}) = \frac{P(\text{data} | \theta) \cdot P(\theta)}{P(\text{data})}$$

| 用語 | 記号 | 意味 |
|------|------|------|
| **事後分布** | $P(\theta \| \text{data})$ | データを観測した後のパラメータの信念 |
| **尤度** | $P(\text{data} \| \theta)$ | パラメータ $\theta$ のもとでデータが観測される確率 |
| **事前分布** | $P(\theta)$ | データを観測する前のパラメータへの信念 |
| **周辺尤度** | $P(\text{data})$ | 正規化定数（定数なので無視することも多い） |

### 頻度論（Frequentist）との比較

| 観点 | ベイズ統計 | 頻度論 |
|------|-----------|--------|
| 確率の定義 | 信念の度合い（主観確率） | 試行を無限回繰り返したときの相対頻度 |
| パラメータ | 不確実な確率変数（分布を持つ） | 未知だが固定の定数 |
| 出力 | パラメータの事後分布 | 点推定値・信頼区間 |
| データが少ないとき | 事前分布が貢献し安定 | 不安定になりやすい |
| 計算コスト | 高い（MCMC等が必要） | 低い（解析解・最適化） |
| 解釈 | 「パラメータが○○の範囲にある確率は95%」 | 「この手順を繰り返すと95%の区間が真値を含む」 |

### 主な用途・使い所

#### ベイズ統計が特に有効な場面

1. **データが少ない（小標本）**: 事前分布で知識を補完できる
2. **不確実性を定量化したい**: 点推定でなく分布を得ることで意思決定の信頼性向上
3. **逐次更新**: 新データが来るたびに事後分布を更新（事後分布が次の事前分布になる）
4. **階層モデル**: グループ構造を持つデータの分析（部分的なデータ共有）
5. **A/Bテスト**: 試験打ち切り基準を確率として解釈できる

#### 具体的なユースケース

| 分野 | 用途 |
|------|------|
| **医療・臨床試験** | 少数例での薬効推定、FDA申請でのベイズ適応デザイン |
| **A/Bテスト** | 途中での試験停止基準、複数バリアント比較 |
| **推薦システム** | コールドスタート問題（データが少ないユーザーへの対応） |
| **金融** | 信用リスク評価、ポートフォリオ最適化 |
| **スパムフィルタ** | ナイーブベイズ分類器（Gmailの基盤技術） |
| **異常検知** | 正常分布を事前分布として異常スコアを計算 |

### 実装ツール

**PyMC（Python）:**

```python
import pymc as pm
import numpy as np

# コイントスの例: 表の確率θを推定
data = np.array([1, 0, 1, 1, 0, 1, 0, 1, 1, 1])  # 1=表, 0=裏

with pm.Model() as model:
    # 事前分布: θ ~ Beta(1, 1) = 一様分布
    theta = pm.Beta("theta", alpha=1, beta=1)

    # 尤度: data ~ Binomial(n=1, p=theta)
    obs = pm.Bernoulli("obs", p=theta, observed=data)

    # MCMCサンプリング
    trace = pm.sample(1000, tune=500, return_inferencedata=True)

pm.plot_posterior(trace, var_names=["theta"])
```

**主なライブラリ比較:**

| ライブラリ | 言語 | 特徴 |
|-----------|------|------|
| **PyMC** | Python | 直感的なモデル記述、NumPy親和性高い |
| **Stan / PyStan** | Python/R | 高速なHMCサンプラー、複雑モデルに強い |
| **Pyro** | Python | PyTorchバックエンド、変分推論対応 |
| **BayesFlow** | Python | シミュレーションベースの推論 |
| **scikit-learn** | Python | ナイーブベイズ・ガウス過程など基本的な手法のみ |

### ベイズ推論の計算手法

| 手法 | 概要 | 向き不向き |
|------|------|-----------|
| **解析的手法** | 共役事前分布を使い閉形式で計算 | シンプルなモデルのみ |
| **MCMC（マルコフ連鎖モンテカルロ法）** | サンプリングで事後分布を近似 | 精度高いが計算コスト大 |
| **変分推論（VI）** | 事後分布を最適化問題として近似 | 大規模データ・速度優先 |
| **ラプラス近似** | 事後分布を正規分布で近似 | シンプル・高速 |

## ポイント

- ベイズ統計の本質は「データが来るたびに信念を更新する」という逐次学習の枠組み
- 事前分布の選択はモデルに強い影響を与えるため、ドメイン知識の活用や無情報事前分布の選択が重要
- データが十分に多ければ事前分布の影響は薄れ、頻度論的な推定に収束する
- [[線型モデル]]のRidge回帰はL2正則化=ガウス事前分布、Lasso回帰はL1正則化=ラプラス事前分布のベイズ解釈と等価
- 階層ベイズモデルは「縮小推定（Shrinkage Estimation）」の自然な枠組みで、小サンプルグループの推定精度向上に特に有効

## 関連項目

- [[線型モデル]]
- [[MLOps]]

## 参考

- [What are Bayesian statistics? - IBM](https://www.ibm.com/think/topics/bayesian-statistics)
- [An Introduction to Bayesian Thinking (オンラインブック)](https://statswithr.github.io/book/the-basics-of-bayesian-statistics.html)
- [PyMC Documentation](https://www.pymc.io/)
- [Bayesian Statistics: A Beginner's Guide - QuantStart](https://www.quantstart.com/articles/Bayesian-Statistics-A-Beginners-Guide/)
